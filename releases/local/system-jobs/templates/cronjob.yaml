apiVersion: v1
kind: ServiceAccount
metadata:
  name: system-jobs-admin
secrets: []
imagePullSecrets: []
---
apiVersion: v1
kind: Secret
metadata:
  name: kube-api-secret
  annotations:
    kubernetes.io/service-account.name: system-jobs-admin
type: kubernetes.io/service-account-token
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: system-jobs-admin
subjects:
- kind: ServiceAccount
  name: system-jobs-admin
  namespace: system-tools
- kind: ServiceAccount
  name: system-jobs-admin
  namespace: system-tools
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin

---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: system-jobs
spec:
  schedule: "* * * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  startingDeadlineSeconds: 300
  jobTemplate:
    spec:
      template:
        spec:
          nodeSelector:
            type: system
          tolerations:
            - key: "type"
              operator: "Equal"
              value: "system"
              effect: "NoSchedule"
            - key: "type"
              operator: "Equal"
              value: "system"
              effect: "NoExecute"
          restartPolicy: Never
          serviceAccount: system-jobs-admin
          containers:
            {{ if .Values.cleaner.enabled }}
            - name: cleaner
              image: ghcr.io/ctron/kubectl:latest
              command:
                - /bin/bash
                - -c
                - |
                  # Cleans up workloads
                  kubectl get pods -A {{ if .Values.cleaner.excludeTekton }}| grep -vE "tekton"{{ end }}{{ if .Values.cleaner.excludeCatalogue }}| grep -vE "catalogue"{{ end }}| grep -E "{{ .Values.cleaner.includes }}" | awk '{print "kubectl -n "$1" delete pod "$2}' | bash

                  # Cleans up stale Terminating pods
                  kubectl get pods -A {{ if .Values.cleaner.excludeTekton }}| grep -vE "tekton"{{ end }}{{ if .Values.cleaner.excludeCatalogue }}| grep -vE "catalogue"{{ end }}| grep -E "{{ .Values.cleaner.includes }}" | awk '{print "kubectl -n "$1" delete pod "$2" --force --grace-period=0"}' | bash
            {{ end }}
            {{ if .Values.tainter.enabled }}
            - name: tainter
              image: ghcr.io/ctron/kubectl:latest
              command:
                - /bin/bash
                - -c
                - |

                  {{- range .Values.taints }}
                  kubectl taint node -l {{ .selector.key }}={{ .selector.value }} {{ .taint.key }}={{ .taint.value }}:{{ .taint.effect }} --overwrite
                  {{- end }}
            {{ end }}
            {{ if and .Values.tekton.enabled .Values.tekton.pipeline.cleanup.enabled }}
            - name: cleanup-pr-tr
              image: gcr.io/tekton-releases/dogfooding/tkn
              env:
                - name: KEEP
                  value: "{{ .Values.tekton.pipeline.cleanup.keep.pipelineRuns }}"
                - name: KEEP_TR
                  value: "{{ .Values.tekton.pipeline.cleanup.keep.taskRuns }}"
                - name: NAMESPACE
                  value: "tekton-pipelines"
              command:
              - /bin/sh
              - -c
              - |
                # A safety check, to avoid deleting too much!
                if [[ $KEEP -eq 0 || $KEEP == "" ]]; then
                  echo "This task cannot be used to delete *all* resources from a cluster" >&2
                  echo "Please specifcy a value for keep > 0"
                  exit 1
                fi
                # Cleanup pipelineruns first, as this will delete tasksruns too
                tkn pr delete -n $NAMESPACE --force --keep $KEEP
                # Keep double the amount of tr, for standalone trs
                tkn tr delete -n $NAMESPACE --force --keep $KEEP_TR
            {{ end }}
